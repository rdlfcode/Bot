{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import darts_tools as dt\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.models import TFTModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, rmse\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The (time) index from `df` is monotonically increasing. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Technology'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Define columns and create TimeSeries objects for each ticker\u001b[39;00m\n\u001b[0;32m     17\u001b[0m value_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotected_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m---> 19\u001b[0m stocks \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_group_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Preparing the data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m scalers, trains, vals, past_covariates, future_covariates \u001b[38;5;241m=\u001b[39m [], [], [], [], []\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\darts\\timeseries.py:951\u001b[0m, in \u001b[0;36mTimeSeries.from_group_dataframe\u001b[1;34m(cls, df, group_cols, time_col, value_cols, static_cols, fill_missing_dates, freq, fillna_value, drop_group_cols, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    937\u001b[0m         static_cov_vals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(group[static_cols]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dataframe(\n\u001b[0;32m    940\u001b[0m         df\u001b[38;5;241m=\u001b[39msplit,\n\u001b[0;32m    941\u001b[0m         fill_missing_dates\u001b[38;5;241m=\u001b[39mfill_missing_dates,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         ),\n\u001b[0;32m    949\u001b[0m     )\n\u001b[1;32m--> 951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\darts\\utils\\utils.py:266\u001b[0m, in \u001b[0;36m_parallel_apply\u001b[1;34m(iterator, fn, n_jobs, fn_args, fn_kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallel_apply\u001b[39m(\n\u001b[0;32m    242\u001b[0m     iterator: Iterator[\u001b[38;5;28mtuple\u001b[39m], fn: Callable, n_jobs: \u001b[38;5;28mint\u001b[39m, fn_args, fn_kwargs\n\u001b[0;32m    243\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    Utility function that parallelise the execution of a function over an Iterator\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     returned_data \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m returned_data\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\darts\\timeseries.py:939\u001b[0m, in \u001b[0;36mTimeSeries.from_group_dataframe.<locals>.from_group\u001b[1;34m(static_cov_vals, group)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# add the static covariates to the group values\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     static_cov_vals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(group[static_cols]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstatic_cov_vals\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_static_cov_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mextract_static_cov_cols\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\darts\\timeseries.py:741\u001b[0m, in \u001b[0;36mTimeSeries.from_dataframe\u001b[1;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value, static_covariates, hierarchy)\u001b[0m\n\u001b[0;32m    732\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    734\u001b[0m xa \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[0;32m    735\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mvalues[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[0;32m    736\u001b[0m     dims\u001b[38;5;241m=\u001b[39m(time_index\u001b[38;5;241m.\u001b[39mname,) \u001b[38;5;241m+\u001b[39m DIMS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:],\n\u001b[0;32m    737\u001b[0m     coords\u001b[38;5;241m=\u001b[39m{time_index\u001b[38;5;241m.\u001b[39mname: time_index, DIMS[\u001b[38;5;241m1\u001b[39m]: series_df\u001b[38;5;241m.\u001b[39mcolumns},\n\u001b[0;32m    738\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m{STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},\n\u001b[0;32m    739\u001b[0m )\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_xarray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\darts\\timeseries.py:470\u001b[0m, in \u001b[0;36mTimeSeries.from_xarray\u001b[1;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(xa_)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mxa_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\xarray\\core\\common.py:1458\u001b[0m, in \u001b[0;36mDataWithCoords.astype\u001b[1;34m(self, dtype, order, casting, subok, copy, keep_attrs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(order\u001b[38;5;241m=\u001b[39morder, casting\u001b[38;5;241m=\u001b[39mcasting, subok\u001b[38;5;241m=\u001b[39msubok, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   1456\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m-> 1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_ufunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\xarray\\core\\computation.py:1265\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[1;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m-> 1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_dataarray_vfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables_vfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\xarray\\core\\computation.py:307\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[1;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[0;32m    302\u001b[0m result_coords, result_indexes \u001b[38;5;241m=\u001b[39m build_output_coords_and_indexes(\n\u001b[0;32m    303\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[0;32m    304\u001b[0m )\n\u001b[0;32m    306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 307\u001b[0m result_var \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m out: \u001b[38;5;28mtuple\u001b[39m[DataArray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m DataArray\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\xarray\\core\\computation.py:818\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[1;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n\u001b[0;32m    814\u001b[0m         func \u001b[38;5;241m=\u001b[39m _vectorize(\n\u001b[0;32m    815\u001b[0m             func, signature, output_dtypes\u001b[38;5;241m=\u001b[39moutput_dtypes, exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims\n\u001b[0;32m    816\u001b[0m         )\n\u001b[1;32m--> 818\u001b[0m result_data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    821\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m (result_data,)\n",
      "File \u001b[1;32mc:\\Users\\roman\\Projects\\Bot\\.venv\\Lib\\site-packages\\xarray\\core\\duck_array_ops.py:228\u001b[0m, in \u001b[0;36mastype\u001b[1;34m(data, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mastype(dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mastype(data, dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Technology'"
     ]
    }
   ],
   "source": [
    "# Load settings and data\n",
    "settings = dt.load_settings()\n",
    "\n",
    "# Create copy in .py file format\n",
    "dt.ipynb_to_py(\"darts_test\")\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_CUDA_ALLOC_SYNC'] = \"1\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(settings[\"float_precision\"])\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "df = pd.read_csv(settings[\"data\"])\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "# Define columns and create TimeSeries objects for each ticker\n",
    "value_cols = [col for col in df.columns if col not in settings[\"protected_columns\"]]\n",
    "\n",
    "stocks = TimeSeries.from_group_dataframe(\n",
    "    df,\n",
    "    group_cols=\"Ticker\",\n",
    "    time_col=\"Datetime\",\n",
    "    value_cols=value_cols,\n",
    ")\n",
    "\n",
    "# Preparing the data\n",
    "scalers, trains, vals, past_covariates, future_covariates = [], [], [], [], []\n",
    "\n",
    "# Assuming past covariates are all columns except for 'target'\n",
    "past_covariate_cols = [col for col in value_cols if col != settings[\"target\"]]\n",
    "\n",
    "for stock in stocks:\n",
    "    split = int(len(stock) * settings[\"train_test_pct\"])\n",
    "    train, val = stock[:split], stock[split:]\n",
    "    \n",
    "    # Transforming both past covariates and target series\n",
    "    scaler = Scaler()\n",
    "    target_train_transformed = scaler.fit_transform(train[settings[\"target\"]])\n",
    "    target_val_transformed = scaler.transform(val[settings[\"target\"]])\n",
    "    \n",
    "    # Generate future covariates\n",
    "    future_cov = datetime_attribute_timeseries(stock.time_index, attribute='week', one_hot=False, add_length=settings[\"max_prediction_length\"])\n",
    "    future_cov = future_cov.stack(datetime_attribute_timeseries(stock.time_index, attribute='month', one_hot=False, add_length=settings[\"max_prediction_length\"]))\n",
    "    future_cov = future_cov.stack(datetime_attribute_timeseries(stock.time_index, attribute='quarter', one_hot=False, add_length=settings[\"max_prediction_length\"]))\n",
    "    future_cov = future_cov.astype(np.float32)\n",
    "\n",
    "    cov_scaler = Scaler()\n",
    "    train_future_cov, val_future_cov = future_cov[:len(train)], future_cov[len(train):]\n",
    "    tf_train_future_cov = cov_scaler.fit_transform(train_future_cov)\n",
    "    tf_val_future_cov = cov_scaler.transform(val_future_cov)\n",
    "    future_cov = concatenate([tf_train_future_cov, tf_val_future_cov])\n",
    "\n",
    "    # Generate past covariates\n",
    "    train_past_cov = cov_scaler.fit_transform(train[past_covariate_cols])\n",
    "    val_past_cov = cov_scaler.transform(val[past_covariate_cols])\n",
    "    past_cov = concatenate([train_past_cov, val_past_cov])\n",
    "\n",
    "    scalers.append(scaler)\n",
    "    trains.append(target_train_transformed)\n",
    "    vals.append(target_val_transformed)\n",
    "    past_covariates.append(past_cov)\n",
    "    future_covariates.append(future_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Network, Trainer, and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loggers\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=settings[\"loss_name\"],\n",
    "    patience=10,\n",
    ")\n",
    "ckpt_callback = ModelCheckpoint(\n",
    "    monitor=settings[\"loss_name\"],\n",
    "    dirpath=f\"{settings['base_path']}/{settings['name']}/study_ckpts/\",\n",
    "    filename='{val_loss:.3f}-{epoch:02d}',\n",
    "    every_n_epochs=1,\n",
    ")\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=f\"lightning_logs/lstm_layers_{settings['lstm_layers']}/\", \n",
    "    name=settings[\"name\"],\n",
    ")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "# Define the TFTModel with specified settings\n",
    "model = TFTModel(\n",
    "    input_chunk_length=len(train) // settings[\"n_splits\"],\n",
    "    output_chunk_length=settings[\"max_prediction_length\"],\n",
    "    hidden_size=settings[\"hidden_size\"],\n",
    "    lstm_layers=settings[\"lstm_layers\"],\n",
    "    num_attention_heads=settings[\"attention_head_size\"],\n",
    "    dropout=settings[\"dropout\"],\n",
    "    batch_size=settings[\"batch_size\"],\n",
    "    n_epochs=settings[\"max_train_epochs\"],\n",
    "    likelihood=QuantileRegression(),\n",
    "    optimizer_kwargs={'lr': settings[\"learning_rate\"]},\n",
    "    feed_forward=settings[\"feed_forward\"],\n",
    "    loss_fn=settings[\"loss_func\"],\n",
    "    add_relative_index=True,\n",
    "    add_encoders={\n",
    "        'cyclic': {'future': ['week', 'month', 'quarter'], 'past': ['week', 'month', 'quarter']},\n",
    "        'datetime_attribute': {'future': ['week', 'month', 'quarter'], 'past': ['week', 'month', 'quarter']},\n",
    "        'position': {'past': ['relative'], 'future': ['relative']},\n",
    "        'custom': {'future': [dt.encode_us_holidays], 'past': [dt.encode_us_holidays]},\n",
    "        'transformer': Scaler()\n",
    "    },\n",
    "    pl_trainer_kwargs={\"accelerator\":           settings[\"accelerator\"], \n",
    "                       \"devices\":               -1,\n",
    "                       \"gradient_clip_val\":     settings[\"gradient_clip_val\"],\n",
    "                       \"callbacks\":             [lr_logger,\n",
    "                                                 early_stop_callback,\n",
    "                                                 ckpt_callback,],\n",
    "                        \"logger\":               logger,\n",
    "                        \"enable_checkpointing\": True,\n",
    "                       },\n",
    "    random_state=42,\n",
    "    log_tensorboard=True,\n",
    "    work_dir=settings[\"base_path\"],\n",
    "    use_static_covariates=False,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    series=trains,\n",
    "    past_covariates=past_covariates,\n",
    "    future_covariates=future_covariates,\n",
    "    val_series=vals,\n",
    "    val_past_covariates=past_covariates,\n",
    "    val_future_covariates=future_covariates,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "evaluations = []\n",
    "for train_series, val_series in zip(trains, vals):\n",
    "    pred_series = model.predict(n=settings[\"max_prediction_length\"],\n",
    "                                series=train_series,\n",
    "                                num_loader_workers=20,\n",
    "                                num_jobs=-1,\n",
    "                                )\n",
    "    evaluations.append((mape(val_series, pred_series), rmse(val_series, pred_series)))\n",
    "\n",
    "# Calculating average MAPE and RMSE for simplicity\n",
    "average_mape = sum([eval[0] for eval in evaluations]) / len(evaluations)\n",
    "average_rmse = sum([eval[1] for eval in evaluations]) / len(evaluations)\n",
    "\n",
    "print(f\"Average MAPE: {average_mape}\")\n",
    "print(f\"Average RMSE: {average_rmse}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(settings[\"model_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
