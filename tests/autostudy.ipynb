{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import model_tools as mt\n",
    "from pytorch_forecasting.metrics import MAPE, RMSE, SMAPE, MAE, QuantileLoss\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pytorch_forecasting.metrics.point.MAPE'>\n",
      "Dropped 69 columns due to low feature correlation with target\n",
      "New data shape: (20075, 41)\n",
      "       Ticker  Datetime      open      high       low     close  grossProfit  \\\n",
      "0           0         1 -0.297491 -0.294135 -0.293782 -0.291395    -0.678328   \n",
      "1           0         2 -0.297491 -0.294135 -0.293782 -0.291395    -0.678328   \n",
      "2           0         3 -0.320280 -0.321202 -0.319603 -0.324215    -0.678328   \n",
      "3           0         4 -0.319234 -0.315623 -0.315794 -0.311673    -0.678328   \n",
      "4           0         5 -0.319234 -0.315623 -0.315794 -0.311673    -0.678328   \n",
      "...       ...       ...       ...       ...       ...       ...          ...   \n",
      "20070      10      1821 -0.089255 -0.089375 -0.084887 -0.085275    -0.678328   \n",
      "20071      10      1822 -0.081519 -0.078630 -0.075151 -0.074822    -0.678328   \n",
      "20072      10      1823 -0.069811 -0.074498 -0.085099 -0.092382    -0.678328   \n",
      "20073      10      1824 -0.088000 -0.095160 -0.096527 -0.101999    -0.678328   \n",
      "20074      10      1825 -0.088000 -0.095160 -0.096527 -0.101999    -0.678328   \n",
      "\n",
      "       totalRevenue  operatingIncome  sellingGeneralAndAdministrative  ...  \\\n",
      "0         -0.643203        -0.556704                        -0.730233  ...   \n",
      "1         -0.643203        -0.556704                        -0.730233  ...   \n",
      "2         -0.643203        -0.556704                        -0.730233  ...   \n",
      "3         -0.643203        -0.556704                        -0.730233  ...   \n",
      "4         -0.643203        -0.556704                        -0.730233  ...   \n",
      "...             ...              ...                              ...  ...   \n",
      "20070     -0.643203        -0.556704                        -0.730233  ...   \n",
      "20071     -0.643203        -0.556704                        -0.730233  ...   \n",
      "20072     -0.643203        -0.556704                        -0.730233  ...   \n",
      "20073     -0.643203        -0.556704                        -0.730233  ...   \n",
      "20074     -0.643203        -0.556704                        -0.730233  ...   \n",
      "\n",
      "       operatingCashflow  proceedsFromOperatingActivities  \\\n",
      "0              -0.590522                              0.0   \n",
      "1              -0.590522                              0.0   \n",
      "2              -0.590522                              0.0   \n",
      "3              -0.590522                              0.0   \n",
      "4              -0.590522                              0.0   \n",
      "...                  ...                              ...   \n",
      "20070          -0.590522                              0.0   \n",
      "20071          -0.590522                              0.0   \n",
      "20072          -0.590522                              0.0   \n",
      "20073          -0.590522                              0.0   \n",
      "20074          -0.590522                              0.0   \n",
      "\n",
      "       depreciationDepletionAndAmortization  capitalExpenditures  \\\n",
      "0                                 -0.507693            -0.613183   \n",
      "1                                 -0.507693            -0.613183   \n",
      "2                                 -0.507693            -0.613183   \n",
      "3                                 -0.507693            -0.613183   \n",
      "4                                 -0.507693            -0.613183   \n",
      "...                                     ...                  ...   \n",
      "20070                             -0.507693            -0.613183   \n",
      "20071                             -0.507693            -0.613183   \n",
      "20072                             -0.507693            -0.613183   \n",
      "20073                             -0.507693            -0.613183   \n",
      "20074                             -0.507693            -0.613183   \n",
      "\n",
      "       changeInInventory  profitLoss  cashflowFromInvestment  \\\n",
      "0              -0.187474   -0.537749                0.447157   \n",
      "1              -0.187474   -0.537749                0.447157   \n",
      "2              -0.187474   -0.537749                0.447157   \n",
      "3              -0.187474   -0.537749                0.447157   \n",
      "4              -0.187474   -0.537749                0.447157   \n",
      "...                  ...         ...                     ...   \n",
      "20070          -0.187474   -0.537749                0.447157   \n",
      "20071          -0.187474   -0.537749                0.447157   \n",
      "20072          -0.187474   -0.537749                0.447157   \n",
      "20073          -0.187474   -0.537749                0.447157   \n",
      "20074          -0.187474   -0.537749                0.447157   \n",
      "\n",
      "       paymentsForRepurchaseOfCommonStock  paymentsForRepurchaseOfEquity  \\\n",
      "0                                -0.48953                      -0.475599   \n",
      "1                                -0.48953                      -0.475599   \n",
      "2                                -0.48953                      -0.475599   \n",
      "3                                -0.48953                      -0.475599   \n",
      "4                                -0.48953                      -0.475599   \n",
      "...                                   ...                            ...   \n",
      "20070                            -0.48953                      -0.475599   \n",
      "20071                            -0.48953                      -0.475599   \n",
      "20072                            -0.48953                      -0.475599   \n",
      "20073                            -0.48953                      -0.475599   \n",
      "20074                            -0.48953                      -0.475599   \n",
      "\n",
      "       proceedsFromRepurchaseOfEquity  \n",
      "0                            0.443696  \n",
      "1                            0.443696  \n",
      "2                            0.443696  \n",
      "3                            0.443696  \n",
      "4                            0.443696  \n",
      "...                               ...  \n",
      "20070                        0.443696  \n",
      "20071                        0.443696  \n",
      "20072                        0.443696  \n",
      "20073                        0.443696  \n",
      "20074                        0.443696  \n",
      "\n",
      "[20075 rows x 41 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20075 entries, 0 to 20074\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Ticker                                 20075 non-null  uint8  \n",
      " 1   Datetime                               20075 non-null  int32  \n",
      " 2   open                                   20075 non-null  float64\n",
      " 3   high                                   20075 non-null  float64\n",
      " 4   low                                    20075 non-null  float64\n",
      " 5   close                                  20075 non-null  float64\n",
      " 6   grossProfit                            20075 non-null  float64\n",
      " 7   totalRevenue                           20075 non-null  float64\n",
      " 8   operatingIncome                        20075 non-null  float64\n",
      " 9   sellingGeneralAndAdministrative        20075 non-null  float64\n",
      " 10  researchAndDevelopment                 20075 non-null  float64\n",
      " 11  operatingExpenses                      20075 non-null  float64\n",
      " 12  depreciationAndAmortization            20075 non-null  float64\n",
      " 13  incomeBeforeTax                        20075 non-null  float64\n",
      " 14  incomeTaxExpense                       20075 non-null  float64\n",
      " 15  netIncomeFromContinuingOperations      20075 non-null  float64\n",
      " 16  comprehensiveIncomeNetOfTax            20075 non-null  float64\n",
      " 17  ebit                                   20075 non-null  float64\n",
      " 18  ebitda                                 20075 non-null  float64\n",
      " 19  netIncome                              20075 non-null  float64\n",
      " 20  totalAssets                            20075 non-null  float64\n",
      " 21  totalCurrentAssets                     20075 non-null  float64\n",
      " 22  cashAndCashEquivalentsAtCarryingValue  20075 non-null  float64\n",
      " 23  cashAndShortTermInvestments            20075 non-null  float64\n",
      " 24  currentNetReceivables                  20075 non-null  float64\n",
      " 25  propertyPlantEquipment                 20075 non-null  float64\n",
      " 26  shortTermInvestments                   20075 non-null  float64\n",
      " 27  otherCurrentLiabilities                20075 non-null  float64\n",
      " 28  totalShareholderEquity                 20075 non-null  float64\n",
      " 29  retainedEarnings                       20075 non-null  float64\n",
      " 30  commonStock                            20075 non-null  float64\n",
      " 31  operatingCashflow                      20075 non-null  float64\n",
      " 32  proceedsFromOperatingActivities        20075 non-null  float64\n",
      " 33  depreciationDepletionAndAmortization   20075 non-null  float64\n",
      " 34  capitalExpenditures                    20075 non-null  float64\n",
      " 35  changeInInventory                      20075 non-null  float64\n",
      " 36  profitLoss                             20075 non-null  float64\n",
      " 37  cashflowFromInvestment                 20075 non-null  float64\n",
      " 38  paymentsForRepurchaseOfCommonStock     20075 non-null  float64\n",
      " 39  paymentsForRepurchaseOfEquity          20075 non-null  float64\n",
      " 40  proceedsFromRepurchaseOfEquity         20075 non-null  float64\n",
      "dtypes: float64(39), int32(1), uint8(1)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-19 09:42:57,981] A new study created in memory with name: auto\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[I 2024-01-19 11:19:50,200] Trial 0 finished with value: 1.7371195554733276 and parameters: {'lstm_layers': 1, 'gradient_clip_val': 0.011045025541470495, 'hidden_size': 41, 'hidden_continuous_size': 12, 'attention_head_size': 1, 'dropout': 0.24485759167484392, 'learning_rate': 0.1365948732948304}. Best is trial 0 with value: 1.7371195554733276.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=0, state=TrialState.COMPLETE, values=[1.7371195554733276], datetime_start=datetime.datetime(2024, 1, 19, 9, 42, 57, 982354), datetime_complete=datetime.datetime(2024, 1, 19, 11, 19, 50, 200707), params={'lstm_layers': 1, 'gradient_clip_val': 0.011045025541470495, 'hidden_size': 41, 'hidden_continuous_size': 12, 'attention_head_size': 1, 'dropout': 0.24485759167484392, 'learning_rate': 0.1365948732948304}, user_attrs={'train_loss': 4.553297519683838, 'train_loss_step': 1.4929152727127075, 'val_loss': 1.7371195554733276, 'val_SMAPE': 0.956720769405365, 'val_MAE': 0.422690212726593, 'val_RMSE': 0.8545758724212646, 'val_MAPE': 1.7371195554733276, 'train_loss_epoch': 4.553297519683838, 'lstm_layers': 1, 'name': 'auto', 'corr_thresh': 0.25, 'pct': False, 'float_precision': 'medium', 'max_study_epochs': 30, 'max_train_epochs': 200, 'limit_train_batches': 30, 'log_every_n_steps': 30, 'reduce_on_plateau_patience': 10, 'batch_size': 12, 'target': 'close', 'max_prediction_length': 90, 'max_encoder_length': 20075, 'train_test_pct': 0.75, 'n_splits': 7, 'scaling_method': 'z-score', 'ckpt_path': 'C:\\\\Users\\\\roman\\\\Desktop\\\\Bot\\\\config_history\\\\lstm_layers_2\\\\auto_new_dataset\\\\model_ckpts\\\\val_loss=1.110-epoch=00.ckpt'}, system_attrs={}, intermediate_values={}, distributions={'lstm_layers': IntDistribution(high=4, log=False, low=1, step=1), 'gradient_clip_val': FloatDistribution(high=1.0, log=True, low=0.01, step=None), 'hidden_size': IntDistribution(high=100, log=True, low=1, step=1), 'hidden_continuous_size': IntDistribution(high=100, log=True, low=1, step=1), 'attention_head_size': IntDistribution(high=16, log=True, low=1, step=1), 'dropout': FloatDistribution(high=0.3, log=True, low=0.1, step=None), 'learning_rate': FloatDistribution(high=1.0, log=True, low=0.0001, step=None)}, trial_id=0, value=None)\n",
      "Using model path  C:\\Users\\roman\\Desktop\\Bot\\config_history\\lstm_layers_2\\auto_new_dataset\\model_ckpts\\val_loss=1.110-epoch=00.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | MAPE                            | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 1.0 K \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.3 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 90.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 7.0 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 7.0 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 7.0 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 7.0 K \n",
      "11 | lstm_encoder                       | LSTM                            | 13.8 K\n",
      "12 | lstm_decoder                       | LSTM                            | 13.8 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 3.4 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 82    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 8.7 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 6.8 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 3.5 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 7.0 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 3.5 K \n",
      "20 | output_layer                       | Linear                          | 42    \n",
      "----------------------------------------------------------------------------------------\n",
      "183 K     Trainable params\n",
      "0         Non-trainable params\n",
      "183 K     Total params\n",
      "0.735     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae14553f76541bbab968262c61b2a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f191e4a177204f1ba91951a79f45796c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3e374846343e5b4cf1518c155e348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad2359e86ba4df4b87e9e64ca1af978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6d22abcd8d48fea1cbb1d95bededbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a6ebe06a5416f9831dcabe955e182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e042a4e7985f4fdf83e36f317f07bcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cb65d34beb4f8b994f42779c9e430b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba7c3ab16074712b043b3d99b1324d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a36b00a3b0497898b5b9ece78ee734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9d9d3f3986441fb14091330bcb46ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5936646a5b1240aabd1364d011dd52ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73b9a66b1914c5483b7ce294f2c76e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study loaded successfully.\n",
      "Dropped 106 columns due to low feature correlation with target\n",
      "New data shape: (38324, 4)\n",
      "       Ticker  Datetime  proceedsFromOperatingActivities  close (%)\n",
      "1           0         2                              0.0  -0.012243\n",
      "2           0         3                              0.0  -0.670277\n",
      "3           0         4                              0.0   0.267000\n",
      "4           0         5                              0.0  -0.012243\n",
      "5           0         6                              0.0  -0.012243\n",
      "...       ...       ...                              ...        ...\n",
      "38320      20      1821                              0.0  -0.001430\n",
      "38321      20      1822                              0.0   0.032741\n",
      "38322      20      1823                              0.0  -0.071222\n",
      "38323      20      1824                              0.0  -0.143883\n",
      "38324      20      1825                              0.0  -0.012243\n",
      "\n",
      "[38324 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38324 entries, 1 to 38324\n",
      "Data columns (total 4 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Ticker                           38324 non-null  uint8  \n",
      " 1   Datetime                         38324 non-null  int32  \n",
      " 2   proceedsFromOperatingActivities  38324 non-null  float64\n",
      " 3   close (%)                        38324 non-null  float64\n",
      "dtypes: float64(2), int32(1), uint8(1)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m         settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m     15\u001b[0m         mt\u001b[38;5;241m.\u001b[39mstart_study(settings)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m     13\u001b[0m settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roman\\Desktop\\Bot\\model_tools.py:536\u001b[0m, in \u001b[0;36mstart_study\u001b[1;34m(settings)\u001b[0m\n\u001b[0;32m    533\u001b[0m training_cutoff \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[num_train][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    534\u001b[0m unknown_reals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m--> 536\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesDataSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatetime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_cutoff\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_encoder_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_encoder_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_encoder_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_encoder_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_prediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_prediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_prediction_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_reals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_varying_unknown_reals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munknown_reals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_relative_time_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m validation \u001b[38;5;241m=\u001b[39m TimeSeriesDataSet\u001b[38;5;241m.\u001b[39mfrom_dataset(training, data, predict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stop_randomization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roman\\miniconda3\\envs\\dev\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:481\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.__init__\u001b[1;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget normalizer is separate and not in scalers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# create index\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# convert to torch tensor for high performance data loading later\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_to_tensors(data)\n",
      "File \u001b[1;32mc:\\Users\\roman\\miniconda3\\envs\\dev\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1290\u001b[0m, in \u001b[0;36mTimeSeriesDataSet._construct_index\u001b[1;34m(self, data, predict_mode)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         missing_groups[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_values(name, missing_groups[\u001b[38;5;28mid\u001b[39m], inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1281\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin encoder length and/or min_prediction_idx and/or min prediction length and/or lags are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo large for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1288\u001b[0m     )\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28mlen\u001b[39m(df_index) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1291\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters should not remove entries all entries - check encoder/decoder lengths and lags\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_index\n",
      "\u001b[1;31mAssertionError\u001b[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    loss_funcs = {\n",
    "    \"val_SMAPE\": SMAPE(), \n",
    "    \"val_MAE\":   MAE(),\n",
    "    \"val_RMSE\":  RMSE(),\n",
    "    \"val_MAPE\":  MAPE(),\n",
    "    }\n",
    "    settings = mt.load_settings()\n",
    "    settings[\"loss_func\"] = loss_funcs.get(settings[\"loss_name\"], QuantileLoss())\n",
    "    print(type(settings[\"loss_func\"]))\n",
    "    for p, name in [(False, \"auto\"), (True, \"auto_pct\")]:\n",
    "        settings[\"pct\"] = p\n",
    "        settings[\"name\"] = name\n",
    "\n",
    "        mt.start_study(settings)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
